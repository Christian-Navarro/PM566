<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Text Mining</title>
    <meta charset="utf-8" />
    <meta name="author" content="Emil Hvitfeldt" />
    <script src="libs/header-attrs-2.3/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="libs/countdown-0.3.5/countdown.js"></script>
    <link rel="stylesheet" href="theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, title-slide

# Text Mining
## PM566 - Week 6
### Emil Hvitfeldt

---






&lt;style type="text/css"&gt;
.orange {color: #EF8633}
&lt;/style&gt;


# Plan for the week

- We will try to turn text into numbers
- Then use tidy principals to explore those numbers

---

![](images/tidytext.png)

---

# Why tidytext?

Works seemlessly with ggplot2, dplyr and tidyr.

**Alternatives:**

**R**: quanteda, tm, koRpus

**Python**: nltk, Spacy, gensim

---

# Alice's Adventures in Wonderland


```r
#devtools::install_github("EmilHvitfeldt/tidygutenbergr")
library(tidyverse)
library(tidygutenbergr)

alice &lt;- alices_adventures()
```

---

# Alice's Adventures in Wonderland


```r
alice
```

```
## # A tibble: 3,330 x 3
##    text                                                                 chapter chapter_name       
##    &lt;chr&gt;                                                                  &lt;int&gt; &lt;chr&gt;              
##  1 "CHAPTER I. Down the Rabbit-Hole"                                          1 Down the Rabbit-Ho…
##  2 ""                                                                         1 Down the Rabbit-Ho…
##  3 "Alice was beginning to get very tired of sitting by her sister on …       1 Down the Rabbit-Ho…
##  4 "bank, and of having nothing to do: once or twice she had peeped in…       1 Down the Rabbit-Ho…
##  5 "book her sister was reading, but it had no pictures or conversatio…       1 Down the Rabbit-Ho…
##  6 "it, 'and what is the use of a book,' thought Alice 'without pictur…       1 Down the Rabbit-Ho…
##  7 "conversations?'"                                                          1 Down the Rabbit-Ho…
##  8 ""                                                                         1 Down the Rabbit-Ho…
##  9 "So she was considering in her own mind (as well as she could, for …       1 Down the Rabbit-Ho…
## 10 "hot day made her feel very sleepy and stupid), whether the pleasur…       1 Down the Rabbit-Ho…
## # … with 3,320 more rows
```

---

# Tokenizing

Turning text into smaller units

--

In English:

- split by spaces
- more advanced algorithms

---

# Spacy tokenizer

![](images/spacy.png)

---

# Turning the data into a tidy format


```r
library(tidytext)
alice %&gt;%
  unnest_tokens(token, text)
```

```
## # A tibble: 26,683 x 3
##    chapter chapter_name         token    
##      &lt;int&gt; &lt;chr&gt;                &lt;chr&gt;    
##  1       1 Down the Rabbit-Hole chapter  
##  2       1 Down the Rabbit-Hole i        
##  3       1 Down the Rabbit-Hole down     
##  4       1 Down the Rabbit-Hole the      
##  5       1 Down the Rabbit-Hole rabbit   
##  6       1 Down the Rabbit-Hole hole     
##  7       1 Down the Rabbit-Hole alice    
##  8       1 Down the Rabbit-Hole was      
##  9       1 Down the Rabbit-Hole beginning
## 10       1 Down the Rabbit-Hole to       
## # … with 26,673 more rows
```

---

# Words as a unit

Now that we have words as the observation unit we can use the **dplyr** toolbox.

---

# Using dplyr verbs

.pull-left[

```r
library(dplyr)
alice %&gt;%
  unnest_tokens(token, text)
```
]

.pull-right[

```
## # A tibble: 26,683 x 3
##    chapter chapter_name         token    
##      &lt;int&gt; &lt;chr&gt;                &lt;chr&gt;    
##  1       1 Down the Rabbit-Hole chapter  
##  2       1 Down the Rabbit-Hole i        
##  3       1 Down the Rabbit-Hole down     
##  4       1 Down the Rabbit-Hole the      
##  5       1 Down the Rabbit-Hole rabbit   
##  6       1 Down the Rabbit-Hole hole     
##  7       1 Down the Rabbit-Hole alice    
##  8       1 Down the Rabbit-Hole was      
##  9       1 Down the Rabbit-Hole beginning
## 10       1 Down the Rabbit-Hole to       
## # … with 26,673 more rows
```
]

---

# Using dplyr verbs

.pull-left[

```r
library(dplyr)
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  count(token)
```
]

.pull-right[

```
## # A tibble: 2,628 x 2
##    token          n
##    &lt;chr&gt;      &lt;int&gt;
##  1 _i_            2
##  2 a            632
##  3 abide          1
##  4 able           1
##  5 about         94
##  6 above          3
##  7 absence        1
##  8 absurd         2
##  9 acceptance     1
## 10 accident       2
## # … with 2,618 more rows
```
]

---

# Using dplyr verbs

.pull-left[

```r
library(dplyr)
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  count(token, sort = TRUE)
```
]

.pull-right[

```
## # A tibble: 2,628 x 2
##    token     n
##    &lt;chr&gt; &lt;int&gt;
##  1 the    1643
##  2 and     872
##  3 to      729
##  4 a       632
##  5 she     541
##  6 it      530
##  7 of      514
##  8 said    462
##  9 i       408
## 10 alice   386
## # … with 2,618 more rows
```
]

---

# Using dplyr verbs

.pull-left[

```r
library(dplyr)
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  count(chapter, token)
```
]

.pull-right[

```
## # A tibble: 7,370 x 3
##    chapter token          n
##      &lt;int&gt; &lt;chr&gt;      &lt;int&gt;
##  1       1 a             52
##  2       1 about          8
##  3       1 across         2
##  4       1 actually       1
##  5       1 advice         1
##  6       1 advise         1
##  7       1 afraid         1
##  8       1 after          5
##  9       1 afterwards     1
## 10       1 again          4
## # … with 7,360 more rows
```
]

---

# Using dplyr verbs

.pull-left[

```r
library(dplyr)
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  group_by(chapter) %&gt;%
  count(token) %&gt;%
  top_n(10, n)
```
]

.pull-right[

```
## # A tibble: 121 x 3
## # Groups:   chapter [12]
##    chapter token     n
##      &lt;int&gt; &lt;chr&gt; &lt;int&gt;
##  1       1 a        52
##  2       1 alice    27
##  3       1 and      65
##  4       1 i        30
##  5       1 it       62
##  6       1 of       43
##  7       1 she      79
##  8       1 the      92
##  9       1 to       75
## 10       1 was      53
## # … with 111 more rows
```
]

---

# Using dplyr verbs and ggplot2

.pull-left[

```r
library(dplyr)
library(ggplot2)
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  count(token) %&gt;%
  top_n(10, n) %&gt;%
  ggplot(aes(n, token)) +
  geom_col()
```
]

.pull-right[
&lt;img src="slides_files/figure-html/unnamed-chunk-12-1.png" width="700px" style="display: block; margin: auto;" /&gt;
]

---

# Using dplyr verbs and ggplot2

.pull-left[

```r
library(dplyr)
library(ggplot2)
library(forcats)
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  count(token) %&gt;%
  top_n(10, n) %&gt;%
  ggplot(aes(n, fct_reorder(token, n))) +
  geom_col()
```
]

.pull-right[
&lt;img src="slides_files/figure-html/unnamed-chunk-13-1.png" width="700px" style="display: block; margin: auto;" /&gt;
]

---

# Stop words

A lot of the words don't tell us very much. Words such as "the", "and", "at" and "for" appear a lot in English text but doesn't add much to the context.

Words such as these are called **stop words**

For more information about differences in stop words and when to remove them read this chapter https://smltar.com/stopwords

---

## Stop words in tidytext

tidytext comes with a data.frame of stop words


```r
stop_words
```

```
## # A tibble: 1,149 x 2
##    word        lexicon
##    &lt;chr&gt;       &lt;chr&gt;  
##  1 a           SMART  
##  2 a's         SMART  
##  3 able        SMART  
##  4 about       SMART  
##  5 above       SMART  
##  6 according   SMART  
##  7 accordingly SMART  
##  8 across      SMART  
##  9 actually    SMART  
## 10 after       SMART  
## # … with 1,139 more rows
```

---

# snowball stopwords


```
##   [1] "i"          "me"         "my"         "myself"     "we"         "our"        "ours"      
##   [8] "ourselves"  "you"        "your"       "yours"      "yourself"   "yourselves" "he"        
##  [15] "him"        "his"        "himself"    "she"        "her"        "hers"       "herself"   
##  [22] "it"         "its"        "itself"     "they"       "them"       "their"      "theirs"    
##  [29] "themselves" "what"       "which"      "who"        "whom"       "this"       "that"      
##  [36] "these"      "those"      "am"         "is"         "are"        "was"        "were"      
##  [43] "be"         "been"       "being"      "have"       "has"        "had"        "having"    
##  [50] "do"         "does"       "did"        "doing"      "would"      "should"     "could"     
##  [57] "ought"      "i'm"        "you're"     "he's"       "she's"      "it's"       "we're"     
##  [64] "they're"    "i've"       "you've"     "we've"      "they've"    "i'd"        "you'd"     
##  [71] "he'd"       "she'd"      "we'd"       "they'd"     "i'll"       "you'll"     "he'll"     
##  [78] "she'll"     "we'll"      "they'll"    "isn't"      "aren't"     "wasn't"     "weren't"   
##  [85] "hasn't"     "haven't"    "hadn't"     "doesn't"    "don't"      "didn't"     "won't"     
##  [92] "wouldn't"   "shan't"     "shouldn't"  "can't"      "cannot"     "couldn't"   "mustn't"   
##  [99] "let's"      "that's"     "who's"      "what's"     "here's"     "there's"    "when's"    
## [106] "where's"    "why's"      "how's"      "a"          "an"         "the"        "and"       
## [113] "but"        "if"         "or"         "because"    "as"         "until"      "while"     
## [120] "of"         "at"         "by"         "for"        "with"       "about"      "against"   
## [127] "between"    "into"       "through"    "during"     "before"     "after"      "above"     
## [134] "below"      "to"         "from"       "up"         "down"       "in"         "out"       
## [141] "on"         "off"        "over"       "under"      "again"      "further"    "then"      
## [148] "once"       "here"       "there"      "when"       "where"      "why"        "how"       
## [155] "all"        "any"        "both"       "each"       "few"        "more"       "most"      
## [162] "other"      "some"       "such"       "no"         "nor"        "not"        "only"      
## [169] "own"        "same"       "so"         "than"       "too"        "very"
```

---

# funky stop words quiz #1

.pull-left[
- he's
- she's
- himself
- herself
]

<div class="countdown" id="timer_5f6af353" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">00</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">15</span></code>
</div>

---

# funky stop words quiz #1

.pull-left[
- he's
- .orange[she's]
- himself
- herself
]

.pull-right[
.orange[she's] doesn't appear in the SMART list
]

---

# funky stop words quiz #2

.pull-left[
- owl
- bee
- fify
- system1
]

<div class="countdown" id="timer_5f6af540" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">00</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">15</span></code>
</div>

---

# funky stop words quiz #2

.pull-left[
- owl
- bee
- .orange[fify]
- system1
]

.pull-right[
.orange[fify] was left undetected for 3 years (2012 to 2015) in scikit-learn
]

---

# funky stop words quiz #3

.pull-left[
- substantially
- successfully
- sufficiently
- statistically
]

<div class="countdown" id="timer_5f6af331" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">00</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">15</span></code>
</div>

---

# funky stop words quiz #3

.pull-left[
- substantially
- successfully
- sufficiently
- .orange[statistically]
]

.pull-right[
.orange[statistically] doesn't appear in the Stopwords ISO list
]


---

## Removing stopwords

We can use an `anti_join()` to remove the tokens that also appear in the `stop_words` data.frame

.pull-left[

```r
alice %&gt;%
  unnest_tokens(token, text) %&gt;%
  anti_join(stop_words, by = c("token" = "word")) %&gt;%
  count(token, sort = TRUE)
```
]

.pull-right[

```
## # A tibble: 2,159 x 2
##    token       n
##    &lt;chr&gt;   &lt;int&gt;
##  1 alice     386
##  2 time       71
##  3 queen      68
##  4 king       61
##  5 turtle     57
##  6 mock       56
##  7 gryphon    55
##  8 hatter     55
##  9 head       49
## 10 voice      48
## # … with 2,149 more rows
```
]


---

## Anti-join with same variable name

.pull-left[

```r
alice %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words, by = c("word")) %&gt;%
  count(word, sort = TRUE)
```
]

.pull-right[

```
## # A tibble: 2,159 x 2
##    word        n
##    &lt;chr&gt;   &lt;int&gt;
##  1 alice     386
##  2 time       71
##  3 queen      68
##  4 king       61
##  5 turtle     57
##  6 mock       56
##  7 gryphon    55
##  8 hatter     55
##  9 head       49
## 10 voice      48
## # … with 2,149 more rows
```
]


---

# Stop words removed

.pull-left[

```r
alice %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words, by = c("word")) %&gt;%
  count(word, sort = TRUE) %&gt;%
  top_n(10, n) %&gt;%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```
]

.pull-right[
&lt;img src="slides_files/figure-html/unnamed-chunk-20-1.png" width="700px" style="display: block; margin: auto;" /&gt;
]

---

## Which words appears together?

**ngrams** are n consecutive word, we can count these to see what words appears together.

--

- ngram with n = 1 are called unigrams: "which", "words", "appears", "together"
- ngram with n = 2 are called bigrams: "which words", "words appears", "appears together"
- ngram with n = 3 are called trigrams: "which words appears", "words appears together"

---

## Which words appears together?

We can extract bigrams using `unnest_ngrams()` with `n = 2`


```r
alice %&gt;%
  unnest_ngrams(ngram, text, n = 2)
```

```
## # A tibble: 26,671 x 3
##    chapter chapter_name         ngram        
##      &lt;int&gt; &lt;chr&gt;                &lt;chr&gt;        
##  1       1 Down the Rabbit-Hole chapter i    
##  2       1 Down the Rabbit-Hole i down       
##  3       1 Down the Rabbit-Hole down the     
##  4       1 Down the Rabbit-Hole the rabbit   
##  5       1 Down the Rabbit-Hole rabbit hole  
##  6       1 Down the Rabbit-Hole hole alice   
##  7       1 Down the Rabbit-Hole alice was    
##  8       1 Down the Rabbit-Hole was beginning
##  9       1 Down the Rabbit-Hole beginning to 
## 10       1 Down the Rabbit-Hole to get       
## # … with 26,661 more rows
```

---

# Which words appears together?

Tallying up the bi-grams still shows a lot of stop words but it able to pick up retationhips with patients


```r
alice %&gt;%
  unnest_ngrams(ngram, text, n = 2) %&gt;%
  count(ngram, sort = TRUE)
```

```
## # A tibble: 14,719 x 2
##    ngram          n
##    &lt;chr&gt;      &lt;int&gt;
##  1 said the     210
##  2 of the       133
##  3 said alice   116
##  4 in a          97
##  5 and the       82
##  6 in the        80
##  7 it was        76
##  8 to the        69
##  9 the queen     65
## 10 as she        61
## # … with 14,709 more rows
```

---

# Which words appears together?


```r
alice %&gt;%
  unnest_ngrams(ngram, text, n = 2) %&gt;%
  separate(ngram, into = c("word1", "word2"), sep = " ") %&gt;%
  select(word1, word2)
```

```
## # A tibble: 26,671 x 2
##    word1     word2    
##    &lt;chr&gt;     &lt;chr&gt;    
##  1 chapter   i        
##  2 i         down     
##  3 down      the      
##  4 the       rabbit   
##  5 rabbit    hole     
##  6 hole      alice    
##  7 alice     was      
##  8 was       beginning
##  9 beginning to       
## 10 to        get      
## # … with 26,661 more rows
```

---


```r
alice %&gt;%
  unnest_ngrams(ngram, text, n = 2) %&gt;%
  separate(ngram, into = c("word1", "word2"), sep = " ") %&gt;%
  select(word1, word2) %&gt;%
  filter(word1 == "alice")
```

```
## # A tibble: 385 x 2
##    word1 word2  
##    &lt;chr&gt; &lt;chr&gt;  
##  1 alice was    
##  2 alice without
##  3 alice think  
##  4 alice started
##  5 alice after  
##  6 alice had    
##  7 alice to     
##  8 alice had    
##  9 alice had    
## 10 alice soon   
## # … with 375 more rows
```

---


```r
alice %&gt;%
  unnest_ngrams(ngram, text, n = 2) %&gt;%
  separate(ngram, into = c("word1", "word2"), sep = " ") %&gt;%
  select(word1, word2) %&gt;%
  filter(word1 == "alice") %&gt;%
  count(word2, sort = TRUE)
```

```
## # A tibble: 149 x 2
##    word2       n
##    &lt;chr&gt;   &lt;int&gt;
##  1 and        20
##  2 was        17
##  3 thought    12
##  4 as         11
##  5 could      11
##  6 had        11
##  7 said       11
##  8 did        10
##  9 in          9
## 10 replied     9
## # … with 139 more rows
```

---


```r
alice %&gt;%
  unnest_ngrams(ngram, text, n = 2) %&gt;%
  separate(ngram, into = c("word1", "word2"), sep = " ") %&gt;%
  select(word1, word2) %&gt;%
  filter(word2 == "alice") %&gt;%
  count(word1, sort = TRUE)
```

```
## # A tibble: 146 x 2
##    word1           n
##    &lt;chr&gt;       &lt;int&gt;
##  1 said          116
##  2 thought        26
##  3 to             23
##  4 and            16
##  5 poor           11
##  6 at              7
##  7 cried           7
##  8 so              6
##  9 that            5
## 10 caterpillar     3
## # … with 136 more rows
```

---

# TF-IDF

TF: Term frequency  
IDF: Inverse document frequency


TF-IDF: product of TF and IDF

TF gives weight to terms that appear a lot, IDF gives weight to terms that appears in a few documents

---

# TF-IDF with tidytext

.pull-left[

```r
alice %&gt;%
  unnest_tokens(text, text)
```
]

.pull-right[

```
## # A tibble: 26,683 x 3
##    text      chapter chapter_name        
##    &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;               
##  1 chapter         1 Down the Rabbit-Hole
##  2 i               1 Down the Rabbit-Hole
##  3 down            1 Down the Rabbit-Hole
##  4 the             1 Down the Rabbit-Hole
##  5 rabbit          1 Down the Rabbit-Hole
##  6 hole            1 Down the Rabbit-Hole
##  7 alice           1 Down the Rabbit-Hole
##  8 was             1 Down the Rabbit-Hole
##  9 beginning       1 Down the Rabbit-Hole
## 10 to              1 Down the Rabbit-Hole
## # … with 26,673 more rows
```
]

---

# TF-IDF with tidytext

.pull-left[

```r
alice %&gt;%
  unnest_tokens(text, text) %&gt;%
  count(text, chapter)
```
]

.pull-right[

```
## # A tibble: 7,370 x 3
##    text  chapter     n
##    &lt;chr&gt;   &lt;int&gt; &lt;int&gt;
##  1 _i_         2     1
##  2 _i_        12     1
##  3 a           1    52
##  4 a           2    48
##  5 a           3    48
##  6 a           4    72
##  7 a           5    59
##  8 a           6    72
##  9 a           7    49
## 10 a           8    56
## # … with 7,360 more rows
```
]

---

# TF-IDF with tidytext

.pull-left[

```r
alice %&gt;%
  unnest_tokens(text, text) %&gt;%
  count(text, chapter) %&gt;%
  bind_tf_idf(text, chapter, n)
```
]

.pull-right[

```
## # A tibble: 7,370 x 6
##    text  chapter     n       tf   idf   tf_idf
##    &lt;chr&gt;   &lt;int&gt; &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 _i_         2     1 0.000471  1.79 0.000843
##  2 _i_        12     1 0.000468  1.79 0.000838
##  3 a           1    52 0.0240    0    0       
##  4 a           2    48 0.0226    0    0       
##  5 a           3    48 0.0280    0    0       
##  6 a           4    72 0.0270    0    0       
##  7 a           5    59 0.0271    0    0       
##  8 a           6    72 0.0275    0    0       
##  9 a           7    49 0.0211    0    0       
## 10 a           8    56 0.0224    0    0       
## # … with 7,360 more rows
```
]

---

# TF-IDF with tidytext

.pull-left[

```r
alice %&gt;%
  unnest_tokens(text, text) %&gt;%
  count(text, chapter) %&gt;%
  bind_tf_idf(text, chapter, n) %&gt;%
  arrange(desc(tf_idf))
```
]

.pull-right[

```
## # A tibble: 7,370 x 6
##    text        chapter     n      tf   idf tf_idf
##    &lt;chr&gt;         &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 dormouse          7    26 0.0112   1.79 0.0201
##  2 turtle           10    29 0.0141   1.39 0.0196
##  3 hatter            7    32 0.0138   1.39 0.0191
##  4 mock             10    28 0.0136   1.39 0.0189
##  5 gryphon          10    31 0.0151   1.10 0.0166
##  6 turtle            9    27 0.0117   1.39 0.0163
##  7 caterpillar       5    25 0.0115   1.39 0.0159
##  8 dance            10    13 0.00632  2.48 0.0157
##  9 mock              9    26 0.0113   1.39 0.0157
## 10 hatter           11    21 0.0110   1.39 0.0153
## # … with 7,360 more rows
```
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
